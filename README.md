# Gesture-Recognition-using-LSTM-and-Leap-Motion-Controller
The "Gesture Recognition using LSTM and Leap Motion Controller" project harnesses the power of deep learning and motion sensing to create a robust and responsive system for interpreting hand gestures by using Tensorflow and Pytorch.
this is only the second part of my project, we have built a robotic arm to perform a gesture based on a speech by a human to be able to the communicate with the people who use sign language 
#NOTES:
1. You need to create 2 virtual environments for the deep learning and 2.7.11 python version for the leap motion sdk.
2. Do not forget to run each environment on a seperated thread.

